/**
 * @brief If the video is still up, this explains it extremely well so you don't have to read:
 * https://www.youtube.com/watch?v=gya7x9H3mV0 
 * PBR (Physically Based Rendering) as used in the rendering community, is a way to render models'
 * surfaces in such a way that they closely mimic the way that light and materials interact.
 * The way this is done is by using fairly complex maths.
 * The main problem we are trying to solve in a fragment shader is that we are trying to caluclate the
 * color of a pixel taking into account all factors that can influence it; although at first it appears
 * a simple problem to solve, there are a lot of factors that influence the color the pixel a surface
 * will have.
 *
 * Lets define the following variables and functions:
 * - x: a pixel of a patch of a mesh (triangle). This is what we are trying to find the color of and is the instance
 *   on which we are running the fragment shader
 * - n: the normal vector of pixel x. Remember that the graphics pipeline on a GPU automatically
 *   interpolates the output variables from the vertex shader to the input variables of the fragment shader.
 *   The GPU does this by running the vertex shader once per vertex. After that, for each triangle (the GPU knows
 *   how to identify triangles because of the index buffer provided in the vertex shader) 
 *   the number of pixels to render is calculated between the vertices by the rasterizer, and for each pixel, a set of weights
 *   is also calculated; these weights specify how close the pixel is to each of the vertices. If the pixel's 
 *   weights are (0.5, 0.5, 0.5), it means that the pixel is exactly half way in between the vertices, therefore
 *   every output variable from each run of the vertex shader on the vertices is exactly the average value of all
 *   3 values for that specific pixel, including the normal vector (if specified as output value in the vertex shader of course).
 *   After that, the fragment shader is run once for each calculated pixel, and the interpolated values are used
 *   as input variables (if specified) in the shader run.
 * - s: the hemisphere above pixel x, whose pole is pointed to exactly by n and whose surface is at exactly 1 unit
 *   distance from x
 * - v: the unit vector pointing from the pixel to the virtual camera
 * - l: the unit vector pointing from the pixel to the light source
 * - BRDF: a function that returns the radiance of light reflected by pixel x in direction v, given the
 * - color and intensity of the light source, x and v
 * - Lo: outgoing radiance, represented as a vector of 4 elements with the first 3 elements
 *   being the color defined as RGB values and the 4th element specifying intensity. For example vec4(1.0, 0.0, 0.0, 15.0)
 *   defines a red light with an intensity of 15.0
 * - Le: emitted radiance
 * - Li: incoming radiance
 * 
 * With the variables defined above, we can define the PBR equation:
 * Lo = Le + integral over s with differential -l(BRDF * Li * DotProduct(n, -l))
 * 
 * We'll go over the BRDF shortly, but first let's dissect and explain this a bit.
 * First of all, we need an integral because to calculate the brightness, or amount of light received by the pixel, we need to sum the 
 * light contribution from every single possible direction to pixel x; this is why we are integrating over s with differential -l. 
 * The differential is key to understanding this:
 * in the real world, a point in space or on a surface receives light from all possible directions; to calculate this (the light color
 * and intensity), we need the amount of light contributions coming to the point from all possible directions (from the light source to
 * point x). 
 * We defined l as the unit vector that points from pixel x to light source l, so -l is the unit vector that points from the light
 * source to pixel x, but in our case, the entire surface of hemisphere s is also a light source, so we need a way to consider every
 * single point on the hemisphere as a light source; think of an enviroment map that you would use for image-based lighting in Blender
 * for instance.
 * The integral is the perfect way to do this and is literally saying: for each vector -l pointing from a point on hemishpere s
 * to pixel x, calculate the following: (BRDF * Li * DotProduct(n, -l)) and sum it up.
 * The reason why we are using a hemisphere and not an entire sphere (that would consider all possible directions instead of half) 
 * for this calculation is because, in practice, the vast majority of pixels of a surface we are trying to render is surrounded by 
 * other pixels facing the same direction (with the same normal), which would block the light coming from any direction other than
 * the hemisphere above it. 
 * Having now understood the overall structure of how the equation was derived, lets dive into the details:
 * 
 * First of all, we multiply the incoming light Li by DotProduct(n, -l) because we need to scale the light's intensity. The angle of 
 * incidence between -l and normal n is the defining factor; this is because a surface lit from behind receives no direct light rays
 * from the light source, therefore is 100% dark (although in the real world there is always some indirect light reaching it by 
 * bouncing off something else) whereas if the light rays are striking the surface head on, the transmitted energy is at its maximum,
 * because the photons reaching the surface have a much harder time bouncing off of it, so most of their kinetic energy is absorbed by the
 * material or converted to heat, therefore the surface will be as lit as it can be. The dot product between these 2 vectors gives a scalar value that models this
 * perfectly.
 * 
 * Next, lets dissect the BRDF.
 * BRDF stands for Bidirectional Reflection Distribution Function. The value this function calculates represents the amount of light 
 * that is reflected in a specific direction from a light source, also called radiance.
 * This function was derived by Robert Cook and Kenneth Torrance in 1982.
 * To come up with this function, these 2 clever gentlemen started by posing the question: how do we mathematically model the amount
 * of light that reaches our eyes when it bounces off a surface? You can think of a sphere of polished, shiny metal in a bright, sunny summer
 * day; that bright spot on the surface that reflects sunlight towards our eyes: how do we mathematically model the color and intensity
 * of the light that reaches our eyes on that specific point (or area of the surface) with that specific light source (the sun)?
 * 
 * To explain this, we need to introduce some important terminology, discovered and defined by many smart people over the years:
 * 1) Radiant flux: this is simply the total amount of photon energy per second radiated by a light source. Most of the energy a light source emits 
 *    is usually emitted as heat, but we are interested in the energy carried by the photons leaving the light source, and this is what the
 *    radiant flux measures. The energy a photon carries is mostly kinetic energy and is given by (Pc * C) / Wl, where
 *    Pc is Planck's constant, C is light speed in m/s and Wl is the photon's wave length (a.k.a color for us humans) in meters. In this case,
 *    Planck's constant is a way to quantify the mass the photon has (even though photons are mass-less) so we can use it with our existing kinetic 
 *    energy equations for objects that have a mass, although it is much more complicated than that; see https://en.wikipedia.org/wiki/Planck_constant 
 *    for more information.
 * 
 *    Radiant flux is measured in Watts, which corresponds to Joules per second (J/s). Lets break this down: 
 *    One Joule is the work done (or energy expended) by a force of one newton (N) moving an object a distance of one meter (m) in a vacuum where there is no friction. 
 *    One Newton equals a force that produces an acceleration of one meter per second (s) squared on a one kilogram (kg) mass. This means that
 *    applying a constant force of 1 Newton to a 1 Kg object (in a vacuum where there is no friction) will result in the object going 1 meter per 
 *    second faster each second, or it can also mean that applying a force of 1 Newton for 1 second to a 1 Kg object in a vacuum, causes the object to move 1 meter. 
 *    Therefore, one Joule equals one Newton * meter.
 *
 *    To quantify this in a way that you can actually imagine it, imagine being on very smooth, perfectly flat ice (to "simulate" a vacuum), with a 60 Kg, mirror-smooth, cube of 
 *    metal sat on the surface. Now imagine that you have magic shoes that give you perfect grip on the ice; you lean forward, grab the cube from an edge and you push it 
 *    explosively, so that it slides a distance of 1 meter in 1 second. Can you imagine the amount of force you would need to exert with your muscles to do that?
 *    That pushing force you just exerted is roughly the equivalent of 60 Joules, therefore a light emitting 60 Watts of energy is roughly equivalent to the energy
 *    you would expend pushing the 60 Kg cube of metal on ice for one meter each second (from stationary). So you can picture yourself pushing the 60 Kg cube 1 meter 
 *    in one second, then have the cube magically stop, as if it hit an invisible brick wall. You would then approach the stationary cube again and push it 1 meter 
 *    in 1 second again and then have it stop again. This is roughly the equivalent energy required to keep a 60 Watt light on continuously (keep in mind that most energy
 *    emitted will be heat, as photons in general carry very little energy). 
 *    This also gives you an idea of how energetically expensive it is to keep a 1000 watt heater on, for example. It would be like you pushing a 1 ton metal cube on ice from 
 *    stationary for a distance of 1 meter each second, over, and over and over again. Pretty insane...
 * 
 * 2) Radiant intensity: this is the amount of photon energy emitted by a light source in a particular cone. You may have seen spot lights in games, 
 *    where a light illuminates only an exact cone; because this cone is particularly useful, someone gave it a name and also a unit of measurement. 
 *    It is called a solid angle, and it is measured in steradians; it basically quantifies the volume of a field of view.
 *    From wikipedia: The steradian (symbol: sr) or square radian is the unit of solid angle in the International System of Units (SI). It is used in 
 *    three-dimensional geometry, and is analogous to the radian, which quantifies planar angles. Whereas an angle in radians, projected onto a circle, 
 *    gives a length on the circumference, a solid angle in steradians, projected onto a sphere, gives an area on the surface.
 *    So a solid angle is defined by the area on the surface of a sphere projected by a particular cone radiating from the center of the sphere. 
 *    See https://en.wikipedia.org/wiki/Steradian for more detailed maths and info.
 *
 *    The unit of measurement for radiant intensity is Watt per steradian, so that would be the amount of energy per second (Watt) emitted in a
 *    particular cone (steradian) around the light source.
 *
 *    A good example that ties radiant flux and radiant intensity together is the point light: what is the radiant intensity of a point light?
 *    How much energy per steradian is emitted by a point light? To calculate it, we simply take the radiant flux of the point light and divide
 *    it by the solid angle in which the photons emitted by the point light travel, which is in all directions. This means that the solid angle
 *    of a point light is not really a cone, it's the entire volume around it, so it's a sphere. The area of a sphere is 4*Pi, so to find the radiant
 *    intensity of a point light, we use (radiant flux / 4*Pi).
 *
 * 3) Irradiance: this is the photon energy received by a surface per area, and is measured in Watts per square meter (W / m^2). If you think about it, photons
 *    will strike a surface with the most energy when that surface is at a perfectly perpendicular angle to their direction, because most of their kinetic
 *    energy is lost as it's really hard for them to bounce back in the same direction, so they tend to be absorbed by the material much more easily, whereas 
 *    bouncing off a surface at an angle is much easier, so most of the kinetic energy is retained, thus the surface is less lit. Photons also lose energy as 
 *    they travel, so something that is really far away will appear dimmer, infact photon energy decreases quadratically over distance. This means that we can 
 *    come up with a formula to calculate irradiance: given an infinitesimally small point on a surface, the irradiance experienced by that point is the radiant intensity of the
 *    light source (how much power per solid angle) * the angle of indicidence reductor (or the cosine of the angle between the surface normal and the photons
 *    impacting the point) / distance from the point to the light source squared.
 *
 * 4) Radiance: radiance is the total amount of photon energy contained in a specific solid angle, emitted and/or reflected from a specific area on a surface. This is essentially quantifying how much
 *    energy is emitted/reflected off an area on a surface in a particular solid angle.
 *    You can imagine that this quantity would be very useful to know how much energy would be emitted towards a viewer, or a camera's lens. If we can calculate how much photon energy will be
 *    striking a camera's lens looking at a surface, we know how bright it'll appear to the camera, therefore, using this principle, we have a way to render really bright spots that appear
 *    on a surface. 
 *    This unit is measured in Watts per steradian per square meter (W / sr * m^2). This is because the
 *    photon energy emitted / reflected by a surface in a certain solid angle is directly proportional to the energy it receives / emits (mesaured by the
 *    Watts) but is inversely proportional to the solid angle considered and the size of the surface. Why?

 *    Because if the surface we consider receives and/or emits a constant amount of photon energy (radiant flux), the bigger the solid angle radianting outwards from the surface we consider, 
 *    the more spread out the emitted / reflected photon energy will be, so the energy per unit solid angle decreases; likewise, if the incoming/emitted radiant flux is constant on the entirety 
 *    of the considered surface, the bigger the surface considered is, the less photons per square meter bouncing off/emitted by the surface per unit area, therefore the photon 
 *    energy per square meter is reduced.
 *    Just think about your monitor; let's say that a 40x20cm monitor emits 15W of radiant flux from all of its pixels combined. A monitor twice the size (80x40cm) will have 4 times
 *    the amount of pixels, therefore if it emits the same total amount of radiant flux as the 40x20cm, it means that each pixel is 4 times dimmer.
 *
 *    Another factor reducing radiance is the angle between the center-line of the solid angle (cone) considered, and the normal of the considered surface. The bigger the angle between the solid
 *    angle's center line and the surface normal, the smaller the area contributing to the outgoing radiant flux, in that specific direction, will be. It's just as if you were looking at the
 *    monitor you are looking at right now from an angle; you won't see as much surface of the monitor if you view it almost from the side, so the emitted light from the pixels reaching your
 *    eyes is less. You will see the most surface area of the monitor if your line of view is perpendicular with the surface normal of the monitor (assuming it's a flat non-curved monitor).
 *    If you look at the definition of radiant intensity and irradiance, this unit of measurement ties the two together.
 *    
 * Now we have an answer to our original question: "how do we quantify the amount of light that reaches our eyes when it bounces off a surface?" The answer is: we use the definition of radiance.
 * The radiance of a specific point on a surface is what the BRDF tries to model, and this is determined by many factors.
 * For example, the wavelength of light bouncing off a surface towards a specific direction can be influenced by the speed at which the impacted object is moving, relative to the direction the light
 * that bounces off of it is going. This is why certain objects in the night sky can appear red shifted or blue shifted. See https://en.wikipedia.org/wiki/Relativistic_Doppler_effect.
 * 
 * Robert Cook and Kenneth Torrance modeled a BRDF around the idea that every surface is made up of lots of tiny microfacets, all potentially oriented in a different direction, depending on 
 * the roughness of the surface. The rougher the material, the bigger the variety in surface normals for the microfacets. The smaller the roughness (say a perfect mirror), the smaller the 
 * varienty in the surface normals. This causes incoming light rays / emitted light rays that bounce off or are emitted from each microfacet to scatter in different directions 
 * (depending on how rough the surface is).
 *
 * The Cook and Torrance BRDF takes into account 4 factors:
 * 1) Diffuse color: this is basically just the integral (sum) of all incoming light intensities from a hemisphere around the point, which we already discussed.
 * 
 * 2) Fresnel reflectance: this is amount of light reflected from a surface after taking into account the Fresnel effect.
 *    The Fresnel effect was discovered by Augustin-Jean Fresnel. He came up with equations to quantify the ratio between reflected and refracted photon energy when a photon hits a material. 
 *    You can experience this as you are walking down the main street of a city: the glass windows of shops will be very difficult to see through when you are approaching them at an angle, 
 *    but if you are looking at them perpendicular to their surface's normal, you will find that it's much easier to see what's inside the shop. This is because at very big large impact angles,
 *    the percentage of photon energy reflected is higher than the percentage of photon energy refracted inside the material.
 *    
 *    For the BRDF, we are interested in the reflected part, because we are trying to calculate the light that reaches our eyes to know how bright a pixel should be, therfore know its color. 
 *    To calculate this, we would need to take into account the density of the materials the photons are travelling through and the angle of incidence of the incoming light relative to the surface's 
 *    normal. The denser the material, the bigger the impact on the photon's direction deviation (refraction). 
 *    As photons hit a material, they will bend towards the hit surface's normal, and the amount of bending is determined by the difference in optical densities 
 *    between the 2 materials once the photon hits the surface. This is modelled by Snell's law. You can find the math implementation here: https://en.wikipedia.org/wiki/Snell%27s_law.
 *    For the reflected part, we use Fresnel's equations. The math is quite complex, but can be found here: https://en.wikipedia.org/wiki/Fresnel_equations.
 *
 * 3) Distribution function: the distribution function is a way to map a photon's reflected direction once it hits a surface. This is basically the probability that a photon will 
 *    bounce towards the predicted direction. On a perfectly flat surface, light rays will always bounce off with the same angle relative to their incoming direction and the surface's normal; 
 *    this is the predicted direction. The distribution function gives us a way to apply a weight factor when a photon bounces off a surface. Because the microfacets of a surface are just too
 *    many, it's basically impossible to pick an exact direction of where the photons will bounce off, so we just pick a random weight within the boundaries of the distribution function; the 
 *    bigger the weight, the closer the direction of the reflected photon will be to the predicted direction.
 *
 *    You can imagine that the rougher a surface is, the bigger the probability that a photon will bounce off in a completely random direction, because just by chance it hit a microfacet that is
 *    totally misaligned with the normal of the face it's part of. The distribution function gives us a neat way to specify, over N amount of times a photon bounces off a specific microfacet,
 *    with what distribution the photons will travel with a similar direction to the predicted bounce direction. Over a certain amount of bounces, this will kinda give you a solid angle whose 
 *    center line is the predicted bounce direction, and the area surrounding it represents a volume in which the photons will have travelled.
 *    The higher the weight, the smaller the solid angle, which means a smaller roughness, which means the more mirror-like the material will appear, because for each microfacet, the light bounces
 *    in the same direction as the face normal each time.
 *
 * 3) Geometric factor: this factor takes into account the fact that the light hitting a microfacet and bouncing towards your eyes might be partly masked by another microfacet. Imagine driving
 *    on a straight hilly road. As you drive, you start approaching a large dip, where the road slopes downwards before going back uphill again. Of course, you can only see the bit further away from you,
 *    the one that goes uphill, at first, because the bit that slopes down is blocked by the horizon.
 *    This is the effect modeled by the geometric factor. The amount of light that bounces off a microfacet (the upwards slope in our example of the road) and reaches your eyes might be influenced 
 *    by how much of that microfacet is actually visible to you, because it could be blocked by the face's horizon. You could imagine that this effect would only be noticeable at very large viewing angles.
 *    The result of this effect is just less light reaching your eyes from the affected microfacets, so technically speaking it's a reduced radiant flux emitted from the microfacet.
 *
 *    The 2 main factors that influence this are the viewing angle compared to the face's normal the microfacet is a part of, and the roughness of the material. The higher the viewing angle,
 *    the more likely the microfacet is masked by the face's horizon. The higher the roughness, the steeper the dip between the microfacets is likely to be, so you will be able to see less of
 *    the microfacet's surface, therefore the total radiant flux reaching your eyes is reduced. This could easily be modelled by a function that takes these 2 parameters and spits out 1 when
 *    the viewing angle is 0 and the roughness is 0, but spits out a very small number as the angle approaches 90 degrees and the roughness approaches 1.
 */